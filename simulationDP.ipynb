{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "occasional-syria",
   "metadata": {},
   "source": [
    "### Computational simulation for Multi-Armed Bandit with Dynamic Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "changed-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-scanner",
   "metadata": {},
   "source": [
    "#### set-up the environment: bandit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "parental-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bandit:  # Environment\n",
    "    def __init__(self, total_round, start_round):\n",
    "        self.total_round = total_round\n",
    "        self.current_round = start_round\n",
    "\n",
    "    def set(self, rewards, actions):\n",
    "        '''\n",
    "        rewards --> dict: round: list of rewards (for each arm)\n",
    "        actions --> dict: round: list of actions (select which arm) should be [0,1,2,3]\n",
    "        '''\n",
    "        self.rewards = rewards\n",
    "        self.actions = actions\n",
    "\n",
    "    def set_state(self, round):\n",
    "        '''\n",
    "        s --> tuple: (int,int)\n",
    "        '''\n",
    "        self.current_round = round\n",
    "\n",
    "    def current_state(self):\n",
    "        return self.current_round\n",
    "\n",
    "    def is_terminal(self, round):\n",
    "        return round != self.total_round\n",
    "\n",
    "    def game_over(self):\n",
    "        return self.current_round == self.total_round\n",
    "\n",
    "    def move(self, action):\n",
    "        # return reward if any\n",
    "        self.current_round += 1\n",
    "        return self.rewards[self.current_round][action]\n",
    "\n",
    "    def all_states(self):\n",
    "        '''\n",
    "        gives us a set of all possible states in grid world\n",
    "        '''\n",
    "        return range(self.total_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-bernard",
   "metadata": {},
   "source": [
    "#### set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "imperial-winter",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 1e-4\n",
    "GAMMA = 1\n",
    "number_of_turns = 40\n",
    "number_of_slot_machines = 4\n",
    "conversion_rate = [0.9 for i in range(number_of_slot_machines)]\n",
    "ACTIONS = list(range(number_of_slot_machines))\n",
    "sim_total = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-pioneer",
   "metadata": {},
   "source": [
    "#### play the game via DP (value iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "loaded-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_df = []\n",
    "raw_policies_df = []\n",
    "sum_policies_df = []\n",
    "\n",
    "sim_total = sim_total\n",
    "for sim in range(sim_total):\n",
    "    \n",
    "    '''\n",
    "    create new dataset each time\n",
    "    '''\n",
    "    def bandit(number_of_turns, conversion_rate, number_of_slot_machines):\n",
    "        bandit = Bandit(total_round=number_of_turns, start_round=0)\n",
    "\n",
    "        np.random.seed(int(time.time()))\n",
    "        rewards_np = np.zeros((number_of_turns, number_of_slot_machines))\n",
    "        for slot_machine_index in range(number_of_slot_machines):\n",
    "            rewards_np[\n",
    "                np.random.choice(np.arange(number_of_turns), int(conversion_rate[slot_machine_index] * number_of_turns),\n",
    "                                 replace=False), slot_machine_index] = 1\n",
    "        rewards_df.append(rewards_np)\n",
    "\n",
    "        rewards = {i: rewards_np[i].tolist() for i in range(number_of_turns)}\n",
    "        actions = {i: list(range(number_of_slot_machines)) for i in range(number_of_turns - 1)}\n",
    "    \n",
    "        bandit.set(rewards, actions)\n",
    "        return bandit\n",
    "\n",
    "    # instantiate the bandit\n",
    "    B = bandit(number_of_turns, conversion_rate, number_of_slot_machines)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    value iteration\n",
    "    '''\n",
    "\n",
    "    # randomly instantiate\n",
    "    policy = {}\n",
    "    for s in B.actions.keys():\n",
    "        policy[s] = np.random.choice(ACTIONS)\n",
    "\n",
    "    # initialize V(s) randomly between 0 and 1\n",
    "    V = {}\n",
    "    states = B.all_states()\n",
    "    for s in states:\n",
    "        if s in B.actions:\n",
    "            V[s] = np.random.random()\n",
    "        else:\n",
    "            # terminal state so we set Value to 0\n",
    "            V[s] = 0\n",
    "\n",
    "    # repeat until convergence\n",
    "    # V[s] = max[a]{sum[s',r] {p(s',r|s,a)[r + GAMMA * V[s']]}}\n",
    "    while True:\n",
    "        max_change = 0\n",
    "        for s in states:\n",
    "            old_vs = V[s]\n",
    "\n",
    "            # V[s] only has policy if not a terminal state\n",
    "            if s in policy:\n",
    "                new_v = float('-inf')\n",
    "\n",
    "                # find max[a]\n",
    "                # random.shuffle(ACTIONS)\n",
    "                for a in ACTIONS:\n",
    "                    B.set_state(s)\n",
    "                    r = B.move(a)\n",
    "                    v = r + GAMMA * V[B.current_state()]\n",
    "                    if v > new_v:\n",
    "                        new_v = v\n",
    "                V[s] = new_v\n",
    "                max_change = max(max_change, np.abs(old_vs - V[s]))\n",
    "\n",
    "        # when the value function converges break out of the loop\n",
    "        if max_change < thresh:\n",
    "            break\n",
    "\n",
    "    '''\n",
    "    find the optimal policy\n",
    "    '''        \n",
    "    # find a policy that leads to optimal value function\n",
    "    for s in policy.keys():\n",
    "        best_act = None\n",
    "        best_value = float('-inf')\n",
    "        # random.shuffle(ACTIONS)\n",
    "        for a in ACTIONS:\n",
    "            B.set_state(s)\n",
    "            r = B.move(a)\n",
    "            v = r + GAMMA * V[B.current_state()]\n",
    "            if v > best_value:\n",
    "                best_value = v\n",
    "                best_act = a\n",
    "        policy[s] = best_act\n",
    "\n",
    "    # see results\n",
    "    raw_policies_df.append(list(policy.values()))\n",
    "    sum_policies_df.append(Counter(list(policy.values())))\n",
    "    \n",
    "    sim += 1\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-bonus",
   "metadata": {},
   "source": [
    "#### visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "binding-mechanics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize interaction time.\n",
    "widedf = pd.DataFrame(sum_policies_df)\n",
    "widedf['turn'] = list(range(sim_total))\n",
    "longdf = pd.melt(widedf, id_vars=['turn'], value_vars=[0, 1, 2, 3],\n",
    "                var_name='groups', value_name='interaction_time')\n",
    "\n",
    "ax = sns.catplot(x='groups', y='interaction_time', kind=\"bar\", data=longdf)\n",
    "sns.despine(offset=5, trim=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "emerging-frontier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1.]\n",
      " [1. 0. 1. 1.]\n",
      " [0. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 0. 1.]\n",
      " [1. 1. 1. 0.]\n",
      " [1. 0. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [0. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 0.]\n",
      " [1. 1. 0. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 0. 1. 0.]\n",
      " [1. 0. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [0. 1. 1. 1.]\n",
      " [1. 1. 0. 1.]]\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(rewards_df[0])\n",
    "print(raw_policies_df[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
